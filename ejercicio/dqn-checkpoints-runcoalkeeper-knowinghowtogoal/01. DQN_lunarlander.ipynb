{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning para _lunar lander_\n",
    "\n",
    "[**Juan Gómez Romero**](https://decsai.ugr.es/~jgomez)  \n",
    "Departamento de Ciencias de la Computación e Inteligencia Artificial  \n",
    "Universidad de Granada  \n",
    "This work is licensed under the [GNU General Public License v3.0](https://choosealicense.com/licenses/gpl-3.0/).\n",
    "\n",
    "---\n",
    "Ejemplo basado en:\n",
    "> Udacity (2019) Deep Reinforcement Learning Course. Disponible en [GitHub](https://github.com/udacity/deep-reinforcement-learning/tree/master/dqn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gfootball.env as football_env\n",
    "from dqn_agent_simultaneous_update import Agent\n",
    "from gfootball.env import football_action_set\n",
    "\n",
    "env = football_env.create_environment(\n",
    "    env_name='academy_run_to_score_with_keeper', \n",
    "    stacked=False,                           # solo estado, no pixeles \n",
    "    representation='simple115',              # solo estado, no pixeles \n",
    "    rewards='scoring,checkpoints',           # recompensas intermedias, no solo al marcar Currently supported rewards are 'scoring' and 'checkpoints'.\n",
    "    render=False)                            # mostrar graficamente\n",
    "\n",
    "agent = Agent(state_size=115, action_size=21, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo\n",
    "A continuación se proporciona una implementación genérica del algoritmo Deep Q-Learning (DQN) y su aplicación a [LunarLander-v2](https://gym.openai.com/envs/LunarLander-v2/).\n",
    "\n",
    "Se considera que el entorno [LunarLander-v2](https://gym.openai.com/envs/LunarLander-v2/) está resuelto cuando se obtienen más de $200$ puntos de media durante 100 episodios consecutivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 50\tPuntuacion media (50 anteriores): -0.03\n",
      "Epsilon actual 0.299251\n",
      "Episodio 100\tPuntuacion media (50 anteriores): -0.13\n",
      "Epsilon actual 0.298504\n",
      "Episodio 150\tPuntuacion media (50 anteriores): -0.05\n",
      "Epsilon actual 0.297758\n",
      "Episodio 200\tPuntuacion media (50 anteriores): -0.02\n",
      "Epsilon actual 0.297015\n",
      "Episodio 250\tPuntuacion media (50 anteriores): 0.10\n",
      "Epsilon actual 0.296273\n",
      "Episodio 300\tPuntuacion media (50 anteriores): 0.06\n",
      "Epsilon actual 0.295533\n",
      "Episodio 350\tPuntuacion media (50 anteriores): 0.02\n",
      "Epsilon actual 0.294796\n",
      "Episodio 400\tPuntuacion media (50 anteriores): -0.07\n",
      "Epsilon actual 0.294059\n",
      "Episodio 450\tPuntuacion media (50 anteriores): 0.12\n",
      "Epsilon actual 0.293325\n",
      "Episodio 500\tPuntuacion media (50 anteriores): 0.01\n",
      "Epsilon actual 0.292593\n",
      "Episodio 550\tPuntuacion media (50 anteriores): -0.00\n",
      "Epsilon actual 0.291862\n",
      "Episodio 600\tPuntuacion media (50 anteriores): 0.07\n",
      "Epsilon actual 0.291133\n",
      "Episodio 650\tPuntuacion media (50 anteriores): -0.02\n",
      "Epsilon actual 0.290406\n",
      "Episodio 700\tPuntuacion media (50 anteriores): 0.00\n",
      "Epsilon actual 0.289681\n",
      "Episodio 750\tPuntuacion media (50 anteriores): 0.01\n",
      "Epsilon actual 0.288958\n",
      "Episodio 800\tPuntuacion media (50 anteriores): 0.00\n",
      "Epsilon actual 0.288237\n",
      "Episodio 850\tPuntuacion media (50 anteriores): 0.13\n",
      "Epsilon actual 0.287517\n",
      "Episodio 900\tPuntuacion media (50 anteriores): 0.04\n",
      "Epsilon actual 0.286799\n",
      "Episodio 950\tPuntuacion media (50 anteriores): -0.01\n",
      "Epsilon actual 0.286083\n",
      "Episodio 1000\tPuntuacion media (50 anteriores): 0.10\n",
      "Epsilon actual 0.285368\n",
      "Episodio 1050\tPuntuacion media (50 anteriores): 0.02\n",
      "Epsilon actual 0.284656\n",
      "Episodio 1100\tPuntuacion media (50 anteriores): -0.07\n",
      "Epsilon actual 0.283945\n",
      "Episodio 1150\tPuntuacion media (50 anteriores): -0.03\n",
      "Epsilon actual 0.283236\n",
      "Episodio 1200\tPuntuacion media (50 anteriores): 0.12\n",
      "Epsilon actual 0.282529\n",
      "Episodio 1250\tPuntuacion media (50 anteriores): 0.08\n",
      "Epsilon actual 0.281823\n",
      "Episodio 1300\tPuntuacion media (50 anteriores): 0.05\n",
      "Epsilon actual 0.281120\n",
      "Episodio 1350\tPuntuacion media (50 anteriores): 0.12\n",
      "Epsilon actual 0.280418\n",
      "Episodio 1400\tPuntuacion media (50 anteriores): 0.10\n",
      "Epsilon actual 0.279718\n",
      "Episodio 1450\tPuntuacion media (50 anteriores): 0.04\n",
      "Epsilon actual 0.279019\n",
      "Episodio 1500\tPuntuacion media (50 anteriores): 0.08\n",
      "Epsilon actual 0.278323\n",
      "Episodio 1550\tPuntuacion media (50 anteriores): 0.05\n",
      "Epsilon actual 0.277628\n",
      "Episodio 1600\tPuntuacion media (50 anteriores): 0.04\n",
      "Epsilon actual 0.276934\n",
      "Episodio 1650\tPuntuacion media (50 anteriores): 0.02\n",
      "Epsilon actual 0.276243\n",
      "Episodio 1700\tPuntuacion media (50 anteriores): 0.03\n",
      "Epsilon actual 0.275553\n",
      "Episodio 1750\tPuntuacion media (50 anteriores): 0.00\n",
      "Epsilon actual 0.274865\n",
      "Episodio 1800\tPuntuacion media (50 anteriores): 0.03\n",
      "Epsilon actual 0.274179\n",
      "Episodio 1850\tPuntuacion media (50 anteriores): 0.00\n",
      "Epsilon actual 0.273494\n",
      "Episodio 1900\tPuntuacion media (50 anteriores): 0.06\n",
      "Epsilon actual 0.272811\n",
      "Episodio 1950\tPuntuacion media (50 anteriores): 0.00\n",
      "Epsilon actual 0.272130\n",
      "Episodio 2000\tPuntuacion media (50 anteriores): 0.04\n",
      "Epsilon actual 0.271451\n",
      "Episodio 2050\tPuntuacion media (50 anteriores): 0.07\n",
      "Epsilon actual 0.270773\n",
      "Episodio 2100\tPuntuacion media (50 anteriores): 0.05\n",
      "Epsilon actual 0.270097\n",
      "Episodio 2150\tPuntuacion media (50 anteriores): 0.00\n",
      "Epsilon actual 0.269422\n",
      "Episodio 2200\tPuntuacion media (50 anteriores): 0.03\n",
      "Epsilon actual 0.268750\n",
      "Episodio 2250\tPuntuacion media (50 anteriores): 0.01\n",
      "Epsilon actual 0.268078\n",
      "Episodio 2300\tPuntuacion media (50 anteriores): 0.05\n",
      "Epsilon actual 0.267409\n",
      "Episodio 2350\tPuntuacion media (50 anteriores): 0.04\n",
      "Epsilon actual 0.266741\n",
      "Episodio 2400\tPuntuacion media (50 anteriores): 0.04\n",
      "Epsilon actual 0.266075\n",
      "Episodio 2450\tPuntuacion media (50 anteriores): -0.03\n",
      "Epsilon actual 0.265411\n",
      "Episodio 2500\tPuntuacion media (50 anteriores): -0.00\n",
      "Epsilon actual 0.264748\n",
      "Episodio 2550\tPuntuacion media (50 anteriores): -0.02\n",
      "Epsilon actual 0.264087\n",
      "Episodio 2600\tPuntuacion media (50 anteriores): -0.08\n",
      "Epsilon actual 0.263428\n",
      "Episodio 2650\tPuntuacion media (50 anteriores): 0.02\n",
      "Epsilon actual 0.262770\n",
      "Episodio 2700\tPuntuacion media (50 anteriores): 0.06\n",
      "Epsilon actual 0.262114\n",
      "Episodio 2750\tPuntuacion media (50 anteriores): -0.05\n",
      "Epsilon actual 0.261459\n",
      "Episodio 2800\tPuntuacion media (50 anteriores): 0.05\n",
      "Epsilon actual 0.260807\n",
      "Episodio 2850\tPuntuacion media (50 anteriores): -0.06\n",
      "Epsilon actual 0.260155\n",
      "Episodio 2900\tPuntuacion media (50 anteriores): -0.03\n",
      "Epsilon actual 0.259506\n",
      "Episodio 2950\tPuntuacion media (50 anteriores): 0.01\n",
      "Epsilon actual 0.258858\n",
      "Episodio 3000\tPuntuacion media (50 anteriores): -0.01\n",
      "Epsilon actual 0.258211\n",
      "Episodio 3050\tPuntuacion media (50 anteriores): -0.07\n",
      "Epsilon actual 0.257567\n",
      "Episodio 3100\tPuntuacion media (50 anteriores): -0.02\n",
      "Epsilon actual 0.256924\n",
      "Episodio 3150\tPuntuacion media (50 anteriores): 0.04\n",
      "Epsilon actual 0.256282\n",
      "Episodio 3200\tPuntuacion media (50 anteriores): -0.05\n",
      "Epsilon actual 0.255642\n",
      "Episodio 3250\tPuntuacion media (50 anteriores): -0.06\n",
      "Epsilon actual 0.255004\n",
      "Episodio 3300\tPuntuacion media (50 anteriores): 0.07\n",
      "Epsilon actual 0.254367\n",
      "Episodio 3350\tPuntuacion media (50 anteriores): -0.05\n",
      "Epsilon actual 0.253732\n",
      "Episodio 3400\tPuntuacion media (50 anteriores): -0.09\n",
      "Epsilon actual 0.253098\n",
      "Episodio 3450\tPuntuacion media (50 anteriores): 0.00\n",
      "Epsilon actual 0.252466\n",
      "Episodio 3500\tPuntuacion media (50 anteriores): 0.04\n",
      "Epsilon actual 0.251836\n",
      "Episodio 3550\tPuntuacion media (50 anteriores): 0.01\n",
      "Epsilon actual 0.251207\n",
      "Episodio 3600\tPuntuacion media (50 anteriores): 0.03\n",
      "Epsilon actual 0.250580\n",
      "Episodio 3650\tPuntuacion media (50 anteriores): -0.02\n",
      "Epsilon actual 0.249954\n",
      "Episodio 3700\tPuntuacion media (50 anteriores): 0.07\n",
      "Epsilon actual 0.249330\n",
      "Episodio 3750\tPuntuacion media (50 anteriores): 0.01\n",
      "Epsilon actual 0.248708\n",
      "Episodio 3800\tPuntuacion media (50 anteriores): -0.01\n",
      "Epsilon actual 0.248087\n",
      "Episodio 3850\tPuntuacion media (50 anteriores): -0.07\n",
      "Epsilon actual 0.247467\n",
      "Episodio 3900\tPuntuacion media (50 anteriores): 0.07\n",
      "Epsilon actual 0.246849\n",
      "Episodio 3950\tPuntuacion media (50 anteriores): 0.03\n",
      "Epsilon actual 0.246233\n",
      "Episodio 4000\tPuntuacion media (50 anteriores): 0.04\n",
      "Epsilon actual 0.245618\n",
      "Episodio 4050\tPuntuacion media (50 anteriores): 0.01\n",
      "Epsilon actual 0.245005\n",
      "Episodio 4100\tPuntuacion media (50 anteriores): -0.03\n",
      "Epsilon actual 0.244393\n"
     ]
    }
   ],
   "source": [
    "def dqn(n_episodes=10000, max_t=1000, eps_start=0.3, eps_end=0.003, eps_decay=0.99995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): numero maximo de episodios de entrenamiento (n_episodios)\n",
    "        max_t (int): numero maximo de pasos por episodio (n_entrenamiento)\n",
    "        eps_start (float): valor inicial de epsilon\n",
    "        eps_end (float): valor final de epsilon\n",
    "        eps_decay (float): factor de multiplicacion (por episodio) de epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # puntuaciones de cada episodio\n",
    "    scores_window = deque(maxlen=50)  # puntuaciones de los ultimos 100 episodios\n",
    "    eps = eps_start                    # inicializar epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            \n",
    "            # elegir accion At con politica e-greedy\n",
    "            action = agent.act(state, eps)\n",
    "            \n",
    "            # aplicar At y obtener Rt+1, St+1\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # almacenar <St, At, Rt+1, St+1>\n",
    "            agent.memory.add(state, action, (reward * 10) ** 3, next_state, done)\n",
    "            \n",
    "            # train & update\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            \n",
    "            # avanzar estado\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            if done:\n",
    "                break \n",
    "\n",
    "        scores_window.append(score)       # guardar ultima puntuacion\n",
    "        scores.append(score)              # guardar ultima puntuacion\n",
    "        eps = max(eps_end, eps_decay*eps) # reducir epsilon\n",
    "        \n",
    "        #print('\\rEpisodio {}\\tPuntuacion media (ultimos {:d}): {:.2f}'.format(i_episode, 50, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 50 == 0:\n",
    "            print('\\rEpisodio {}\\tPuntuacion media ({:d} anteriores): {:.2f}'.format(i_episode, 50, np.mean(scores_window)))\n",
    "            print('\\rEpsilon actual {:.6f}'.format(eps))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth') # guardar pesos de agente entrenado\n",
    "        if np.mean(scores_window)>=2.0:\n",
    "            print('\\nProblema resuelto en {:d} episodios!\\tPuntuacion media (ultimos {:d}): {:.2f}'.format(i_episode-50, 50, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth') # guardar pesos de agente entrenado\n",
    "            break\n",
    "    return scores\n",
    "# cargar pesos del fichero `checkpoint-goalempty.pth del agente entrenado previamente sin arquero`\n",
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint-goalempty.pth'))\n",
    "\n",
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Puntuacion')\n",
    "plt.xlabel('Episodio #')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
