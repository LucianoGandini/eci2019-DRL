{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jugador aleatorio con _Football_\n",
    "Ejemplo de jugador aleatorio para el entorno [_Football_](https://github.com/google-research/football) versión `academy_empty_goal_close`. \n",
    "\n",
    "Ejecución local: requiere instalación según [instrucciones](https://github.com/jgromero/eci2019-DRL/blob/master/ejercicio/Instrucciones%20Entorno%20Football.pdf).\n",
    "\n",
    "<!-- \n",
    "<a href=\"http://www.youtube.com/watch?feature=player_embedded&v=F8DcgFDT9sc\" target=\"_blank\"><img src=\"http://img.youtube.com/vi/F8DcgFDT9sc/0.jpg\" \n",
    "alt=\"IMAGE ALT TEXT HERE\" width=\"580\" border=\"3\" /></a> \n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listar versiones del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11_vs_11_easy_stochastic',\n",
       " 'academy_run_to_score',\n",
       " 'academy_empty_goal',\n",
       " '11_vs_11_stochastic',\n",
       " 'academy_3_vs_1_with_keeper',\n",
       " 'academy_empty_goal_close',\n",
       " 'academy_pass_and_shoot_with_keeper',\n",
       " 'academy_run_to_score_with_keeper',\n",
       " 'academy_run_pass_and_shoot_with_keeper',\n",
       " 'academy_corner',\n",
       " 'academy_single_goal_versus_lazy',\n",
       " 'academy_counterattack_easy',\n",
       " '11_vs_11_hard_stochastic',\n",
       " 'academy_counterattack_hard']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gfootball.env import scenario_builder\n",
    "scenario_builder.all_scenarios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gfootball.env as football_env\n",
    "\n",
    "env = football_env.create_environment(\n",
    "    env_name='academy_empty_goal_close', \n",
    "    stacked=False,                           # solo estado, no pixeles \n",
    "    representation='simple115',              # solo estado, no pixeles \n",
    "    with_checkpoints=True,                   # recompensas intermedias, no solo al marcar \n",
    "    render=True)                             # mostrar graficamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorar entorno virtual\n",
    "\n",
    "En primer lugar, vamos a explorar cómo funciona este entorno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada estado es una tupla de 115 elementos. \n",
    "\n",
    "| Información         | Estructura           | Explicación\n",
    "| --------------------|----------------------| ----------------------\n",
    "| Posición del balón  | (x, y, z)            | \n",
    "| Dirección del balón | (x, y, z)            | \n",
    "| Control del balón   | array(3)             | (1, 0, 0): nadie, (0, 1, 0): locales, (0, 0, 1): visitantes \n",
    "| Jugador activo      | array(11)            | codificación de jugador activo en locales\n",
    "| Posiciones locales  | 11 x array(2)        | 11 posiciones (x, y) de cada jugador local\n",
    "| Movimiento locales  | 11 x array(2)        | 11 vectores de movimiento (x, y) de cada jugador local\n",
    "| Posiciones visitantes  | 11 x array(2)     | 11 posiciones (x, y) de cada jugador visitante\n",
    "| Movimiento visitantes  | 11 x array(2)     | 11 vectores de movimiento (x, y) de cada jugador visitante\n",
    "| Modo de juego       | array(7)             | codificación de modo de juego: {NormalMode, KickOffMode, GoalKickMode, FreeKickMode, CornerMode, ThrowInMode, PenaltyMode}\n",
    "\n",
    "En la modalidad `academy_empty_goal_close` solo hay **51 elementos activos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El agente puede realizar 21 acciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[idle,\n",
       " left,\n",
       " top_left,\n",
       " top,\n",
       " top_right,\n",
       " right,\n",
       " bottom_right,\n",
       " bottom,\n",
       " bottom_left,\n",
       " long_pass,\n",
       " high_pass,\n",
       " short_pass,\n",
       " shot,\n",
       " sprint,\n",
       " release_direction,\n",
       " release_sprint,\n",
       " keeper_rush,\n",
       " release_keeper_rush,\n",
       " sliding,\n",
       " dribble,\n",
       " release_dribble]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gfootball.env import football_action_set\n",
    "print(env.action_space)\n",
    "football_action_set.action_set_dict['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agente aleatorio\n",
    "Implementación de un agente aleatorio que juega durante 10 episodios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0723 05:45:50.417626 139907374929728 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0723 05:45:50.418583 139907374929728 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 95, FPS: 4.2, gameFPS: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 1: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0723 05:46:08.071041 139907374929728 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0723 05:46:08.074542 139907374929728 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 76, FPS: 4.3, gameFPS: 5.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 2: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0723 05:46:28.972892 139907374929728 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0723 05:46:28.975742 139907374929728 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 71, FPS: 3.4, gameFPS: 5.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 3: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0723 05:46:48.417890 139907374929728 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0723 05:46:48.422892 139907374929728 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 79, FPS: 4.1, gameFPS: 5.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 4: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0723 05:47:00.183970 139907374929728 observation_processor.py:362] Dump \"score\": count limit reached / disabled\n",
      "I0723 05:47:00.208617 139907374929728 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0723 05:47:00.233077 139907374929728 football_env_wrapper.py:85] Episode reward: 1.00 score: [1, 0], steps: 10, FPS: 0.8, gameFPS: 2.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 5: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0723 05:48:21.365179 139907374929728 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0723 05:48:21.398587 139907374929728 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 336, FPS: 4.1, gameFPS: 4.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 6: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0723 05:48:37.607337 139907374929728 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0723 05:48:37.611739 139907374929728 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 43, FPS: 2.7, gameFPS: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 7: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0723 05:48:57.283819 139907374929728 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0723 05:48:57.286412 139907374929728 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 70, FPS: 3.6, gameFPS: 5.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 8: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0723 05:49:07.033166 139907374929728 observation_processor.py:362] Dump \"score\": count limit reached / disabled\n",
      "I0723 05:49:07.037627 139907374929728 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0723 05:49:07.040479 139907374929728 football_env_wrapper.py:85] Episode reward: 1.00 score: [1, 0], steps: 11, FPS: 1.1, gameFPS: 2.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 9: 2.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    env.reset()\n",
    "    acc_reward = 0\n",
    "\n",
    "    while True:\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        acc_reward += reward \n",
    "    \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print(\"Recomensa episodio {:d}: {:.2f}\".format(i, acc_reward))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para desactivar _logging_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
